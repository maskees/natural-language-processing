{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZdcIoKukZPSlsETE0azpe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maskees/natural-language-processing/blob/main/lab_5_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2d74d03"
      },
      "source": [
        "**Plan:**\n",
        "\n",
        "1.  **Implement POS tagging and identify Named Entities using NLTK and SpaCy:**\n",
        "    *   Apply NLTK for POS tagging and Named Entity Recognition on a given text.\n",
        "    *   Apply SpaCy for POS tagging and Named Entity Recognition on the same text.\n",
        "\n",
        "2.  **Select and preprocess a real-world dataset:**\n",
        "    *   Choose a dataset containing reviews (e.g., firm, product, book, hotel reviews).\n",
        "    *   Remove noise (stopwords, punctuation) from the predictor columns.\n",
        "\n",
        "3.  **Feature Engineering:**\n",
        "    *   Create features such as total word length, number of unique words, and number of bigrams.\n",
        "    *   Create features for POS tags and Named Entity tags."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')"
      ],
      "metadata": {
        "id": "28ruQ-taMYvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29964a52-7a08-4054-abfb-3c37b089e49a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.tokenize import word_tokenize\n",
        "ltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "8LVPzNcLOb-W",
        "outputId": "0794bbf8-f0b6-428e-9e20-8d126430727c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ltk' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-809546002.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mne_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'averaged_perceptron_tagger_eng'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ltk' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"India is a largest democratic country in the entire world\"\n",
        "token=word_tokenize(text)\n",
        "pos_tag(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue35oVo-O4P7",
        "outputId": "0f0dca96-9564-4136-c449-5ed0b0b7c031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('India', 'NNP'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('largest', 'JJS'),\n",
              " ('democratic', 'JJ'),\n",
              " ('country', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('entire', 'JJ'),\n",
              " ('world', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "T1BPEbgVPKuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(text)\n",
        "for i in doc:\n",
        "  print(i,i.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfRJLUC8P2JH",
        "outputId": "83e1336a-6064-41e9-fc5d-e8f1244e5274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "India PROPN\n",
            "is AUX\n",
            "a DET\n",
            "largest ADJ\n",
            "democratic ADJ\n",
            "country NOUN\n",
            "in ADP\n",
            "the DET\n",
            "entire ADJ\n",
            "world NOUN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "yP79RIoQRH_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d42c6c3"
      },
      "source": [
        "file0= open('/content/0_9.txt', 'r').read()\n",
        "file1= open('/content/1_7.txt', 'r').read()\n",
        "file2= open('/content/2_9.txt', 'r').read()\n",
        "file3= open('/content/3_10.txt', 'r').read()\n",
        "file4= open('/content/4_8.txt', 'r').read()\n",
        "file5= open('/content/5_10.txt', 'r').read()\n",
        "file6= open('/content/6_10.txt', 'r').read()\n",
        "file7= open('/content/7_7.txt', 'r').read()\n",
        "file8= open('/content/8_7.txt', 'r').read()\n",
        "file9= open('/content/9_7.txt', 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files=[]\n",
        "for i in range(10):\n",
        "  files.append(eval('file'+str(i)))"
      ],
      "metadata": {
        "id": "HDd3YpVZWrJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_dict = {}\n",
        "for i, file_content in enumerate(files):\n",
        "  token_dict[f'token{i}'] = word_tokenize(file_content)"
      ],
      "metadata": {
        "id": "L1B5RyS1XVes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, pos_tags in pos_dict.items():\n",
        "  print(f\"--- POS tags for {i} ---\")\n",
        "  for j in pos_tags:\n",
        "    if j[1].startswith('NN'):\n",
        "      print(j)\n",
        "  print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQMwLQx7XaiS",
        "outputId": "e67f3acf-51ed-4036-bbb0-aeb181ce7826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- POS tags for pos0 ---\n",
            "('Bromwell', 'NNP')\n",
            "('High', 'NNP')\n",
            "('cartoon', 'NN')\n",
            "('comedy', 'NN')\n",
            "('time', 'NN')\n",
            "('programs', 'NNS')\n",
            "('school', 'NN')\n",
            "('life', 'NN')\n",
            "('Teachers', 'NNPS')\n",
            "('years', 'NNS')\n",
            "('teaching', 'NN')\n",
            "('profession', 'NN')\n",
            "('Bromwell', 'NNP')\n",
            "('High', 'NNP')\n",
            "('satire', 'NN')\n",
            "('reality', 'NN')\n",
            "('Teachers', 'NNPS')\n",
            "('students', 'NNS')\n",
            "('teachers', 'NNS')\n",
            "('pomp', 'NN')\n",
            "('pettiness', 'NN')\n",
            "('situation', 'NN')\n",
            "('schools', 'NNS')\n",
            "('students', 'NNS')\n",
            "('episode', 'NN')\n",
            "('student', 'NN')\n",
            "('school', 'NN')\n",
            "('.........', 'NNS')\n",
            "('..........', 'NNP')\n",
            "('High', 'NNP')\n",
            "('A', 'NNP')\n",
            "('line', 'NN')\n",
            "('INSPECTOR', 'NN')\n",
            "('teachers', 'NNS')\n",
            "('STUDENT', 'NN')\n",
            "('Bromwell', 'NNP')\n",
            "('High', 'NNP')\n",
            "('adults', 'NNS')\n",
            "('age', 'NN')\n",
            "('Bromwell', 'NNP')\n",
            "('High', 'NNP')\n",
            "('pity', 'NN')\n",
            "--------------------\n",
            "--- POS tags for pos1 ---\n",
            "('comedy', 'NN')\n",
            "('cartoons', 'NNS')\n",
            "('South', 'NNP')\n",
            "('Park', 'NNP')\n",
            "('format', 'NN')\n",
            "('adventures', 'NNS')\n",
            "('girls', 'NNS')\n",
            "('Bromwell', 'NNP')\n",
            "('High', 'NNP')\n",
            "('Keisha', 'NNP')\n",
            "('Natella', 'NNP')\n",
            "('Latrina', 'NNP')\n",
            "('sweets', 'NNS')\n",
            "('bitches', 'NNS')\n",
            "('Keisha', 'NNP')\n",
            "('leader', 'NN')\n",
            "('stories', 'NNS')\n",
            "('teachers', 'NNS')\n",
            "('school', 'NN')\n",
            "('principal', 'NN')\n",
            "('Mr.', 'NNP')\n",
            "('Bip', 'NNP')\n",
            "('Maths', 'NNP')\n",
            "('teacher', 'NN')\n",
            "('others', 'NNS')\n",
            "('cast', 'NN')\n",
            "('Lenny', 'NNP')\n",
            "('Henry', 'NNP')\n",
            "('Gina', 'NNP')\n",
            "('Yashere', 'NNP')\n",
            "('EastEnders', 'NNP')\n",
            "('Chrissie', 'NNP')\n",
            "('Watts', 'NNP')\n",
            "('Tracy-Ann', 'NNP')\n",
            "('Oberman', 'NNP')\n",
            "('Smack', 'NNP')\n",
            "('Pony', 'NNP')\n",
            "('Doon', 'NNP')\n",
            "('Mackichan', 'NNP')\n",
            "('Dead', 'NNP')\n",
            "('Ringers', 'NNP')\n",
            "('Mark', 'NNP')\n",
            "('Perry', 'NNP')\n",
            "('Blunder', 'NNP')\n",
            "('Nina', 'NNP')\n",
            "('Conti', 'NNP')\n",
            "('Canada', 'NNP')\n",
            "--------------------\n",
            "--- POS tags for pos2 ---\n",
            "('Bromwell', 'NNP')\n",
            "('High', 'NNP')\n",
            "('nothing', 'NN')\n",
            "('parody', 'NN')\n",
            "('students', 'NNS')\n",
            "('teachers', 'NNS')\n",
            "('South', 'NNP')\n",
            "('London', 'NNP')\n",
            "('Public', 'NNP')\n",
            "('School', 'NNP')\n",
            "('laughter', 'NN')\n",
            "('vulgar', 'NN')\n",
            "('characters', 'NNS')\n",
            "('cross', 'NN')\n",
            "('section', 'NN')\n",
            "('society', 'NN')\n",
            "('society', 'NN')\n",
            "('escapades', 'NNS')\n",
            "('Keisha', 'NNP')\n",
            "('Latrina', 'NNP')\n",
            "('Natella', 'NNP')\n",
            "('protagonists', 'NNS')\n",
            "('want', 'NN')\n",
            "('term', 'NN')\n",
            "('show', 'NN')\n",
            "('subject', 'NN')\n",
            "('correctness', 'NN')\n",
            "('flies', 'NNS')\n",
            "('window', 'NN')\n",
            "('episode', 'NN')\n",
            "('shows', 'NNS')\n",
            "('fun', 'NN')\n",
            "('taboo', 'NN')\n",
            "('subject', 'NN')\n",
            "('Bromwell', 'NNP')\n",
            "('High', 'NNP')\n",
            "--------------------\n",
            "--- POS tags for pos3 ---\n",
            "('world', 'NN')\n",
            "('stage', 'NN')\n",
            "('people', 'NNS')\n",
            "('actors', 'NNS')\n",
            "('something', 'NN')\n",
            "('hell', 'NN')\n",
            "('theatre', 'NN')\n",
            "('pit', 'NN')\n",
            "('theatre', 'NN')\n",
            "('door', 'NN')\n",
            "('audience', 'NN')\n",
            "('participants', 'NNS')\n",
            "('experience', 'NN')\n",
            "('story', 'NN')\n",
            "('br', 'NN')\n",
            "('/', 'NNP')\n",
            "('>', 'NNP')\n",
            "('<', 'NNP')\n",
            "('br', 'NN')\n",
            "('/', 'NNP')\n",
            "('>', 'NNP')\n",
            "('film', 'NN')\n",
            "('experiment', 'NN')\n",
            "('Hey', 'NN')\n",
            "('story', 'NN')\n",
            "('attention', 'NN')\n",
            "('participation', 'NN')\n",
            "('story', 'NN')\n",
            "('story', 'NN')\n",
            "('br', 'NN')\n",
            "('/', 'NNP')\n",
            "('>', 'NNP')\n",
            "('<', 'NNP')\n",
            "('br', 'NN')\n",
            "('/', 'NNP')\n",
            "('>', 'NNP')\n",
            "('Alas', 'NNP')\n",
            "('one', 'NN')\n",
            "--------------------\n",
            "--- POS tags for pos4 ---\n",
            "('FUTZ', 'NNP')\n",
            "('show', 'NN')\n",
            "('movement', 'NN')\n",
            "('New', 'NNP')\n",
            "('York', 'NNP')\n",
            "('1960s', 'NNS')\n",
            "('origins', 'NNS')\n",
            "('Off', 'NNP')\n",
            "('Off', 'NNP')\n",
            "('Broadway', 'NNP')\n",
            "('everyone', 'NN')\n",
            "('funny', 'NN')\n",
            "('tale', 'NN')\n",
            "('love', 'NN')\n",
            "('sex', 'NN')\n",
            "('liberty', 'NN')\n",
            "('revenge', 'NN')\n",
            "('morality', 'NN')\n",
            "('tale', 'NN')\n",
            "('time', 'NN')\n",
            "('Congress', 'NNP')\n",
            "('marriage', 'NN')\n",
            "('Constitution', 'NN')\n",
            "('story', 'NN')\n",
            "('gay', 'NN')\n",
            "('love', 'NN')\n",
            "('sex', 'NN')\n",
            "('norms', 'NNS')\n",
            "('violence', 'NN')\n",
            "('hate', 'NN')\n",
            "('surface', 'NN')\n",
            "('story', 'NN')\n",
            "('man', 'NN')\n",
            "('love', 'NN')\n",
            "('pig', 'NN')\n",
            "('animals', 'NNS')\n",
            "('something', 'NN')\n",
            "('conformity', 'NN')\n",
            "('America.', 'NNP')\n",
            "('<', 'NNP')\n",
            "('br', 'NN')\n",
            "('/', 'NNP')\n",
            "('>', 'NNP')\n",
            "('<', 'NNP')\n",
            "('br', 'NN')\n",
            "('/', 'NNP')\n",
            "('stage', 'NN')\n",
            "('version', 'NN')\n",
            "('acclaim', 'NN')\n",
            "('production', 'NN')\n",
            "('U.S.', 'NNP')\n",
            "('Europe', 'NNP')\n",
            "('others', 'NNS')\n",
            "('kind', 'NN')\n",
            "('theatre', 'NNS')\n",
            "('show', 'NN')\n",
            "('cast', 'NN')\n",
            "('director', 'NN')\n",
            "('Tom', 'NNP')\n",
            "(\"O'Horgan\", 'NNP')\n",
            "('HAIR', 'NNP')\n",
            "('Jesus', 'NNP')\n",
            "('Christ', 'NNP')\n",
            "('Superstar', 'NNP')\n",
            "('Broadway', 'NNP')\n",
            "('br', 'NN')\n",
            "('/', 'NNP')\n",
            "('>', 'NNP')\n",
            "('<', 'NNP')\n",
            "('br', 'NN')\n",
            "('/', 'NNP')\n",
            "('>', 'NNP')\n",
            "('mainstream', 'NN')\n",
            "('easy-to-take', 'NN')\n",
            "('studio', 'NN')\n",
            "('film', 'NN')\n",
            "('piece', 'NN')\n",
            "('way', 'NN')\n",
            "('world', 'NN')\n",
            "--------------------\n",
            "--- POS tags for pos5 ---\n",
            "('middle', 'NN')\n",
            "('film', 'NN')\n",
            "('idea', 'NN')\n",
            "('credits', 'NNS')\n",
            "('title', 'NN')\n",
            "('till', 'NN')\n",
            "('reception', 'NN')\n",
            "('commentators', 'NNS')\n",
            "('side', 'NN')\n",
            "('film', 'NN')\n",
            "('thing', 'NN')\n",
            "('attention', 'NN')\n",
            "('beautiful', 'NN')\n",
            "('score', 'NN')\n",
            "('Coplandesque', 'NNP')\n",
            "('Americana', 'NNP')\n",
            "('style', 'NN')\n",
            "('surprise', 'NN')\n",
            "('score', 'NN')\n",
            "('none', 'NN')\n",
            "('John', 'NNP')\n",
            "('Williams', 'NNP')\n",
            "('True', 'NN')\n",
            "('scores', 'NNS')\n",
            "('Schindler', 'NNP')\n",
            "('List', 'NN')\n",
            "('name', 'NN')\n",
            "('bombasticities', 'NNS')\n",
            "('Star', 'NNP')\n",
            "('Wars', 'NNP')\n",
            "('opinion', 'NN')\n",
            "('Williams', 'NNP')\n",
            "('movie', 'NN')\n",
            "('anything', 'NN')\n",
            "('tenderness', 'NN')\n",
            "('sensitivity', 'NN')\n",
            "('beauty', 'NN')\n",
            "('tender', 'NN')\n",
            "('plot', 'NN')\n",
            "('movie', 'NN')\n",
            "('score', 'NN')\n",
            "('Catch', 'NNP')\n",
            "('Me', 'NNP')\n",
            "('shows', 'NNS')\n",
            "('sophistication', 'NN')\n",
            "('Stanley', 'NNP')\n",
            "('Iris', 'NNP')\n",
            "('education', 'NN')\n",
            "('movies', 'NNS')\n",
            "('How', 'NNP')\n",
            "('Green', 'NNP')\n",
            "('Valley', 'NNP')\n",
            "('Konrack', 'NNP')\n",
            "('John', 'NNP')\n",
            "('Voigt', 'NNP')\n",
            "('charges', 'NNS')\n",
            "('South', 'NNP')\n",
            "('Carolina', 'NNP')\n",
            "('Danny', 'NNP')\n",
            "('Renaissance', 'NNP')\n",
            "('Man', 'NNP')\n",
            "('story', 'NN')\n",
            "('awakening', 'NN')\n",
            "('story', 'NN')\n",
            "('addition', 'NN')\n",
            "('genre', 'NN')\n",
            "--------------------\n",
            "--- POS tags for pos6 ---\n",
            "('Fair', 'NNP')\n",
            "('story', 'NN')\n",
            "('movie', 'NN')\n",
            "('lives', 'NNS')\n",
            "('people', 'NNS')\n",
            "('life', 'NN')\n",
            "('love.The', 'NN')\n",
            "('acting', 'NN')\n",
            "('film', 'NN')\n",
            "('cinematography', 'NN')\n",
            "('screenplay', 'NN')\n",
            "('story/script', 'NN')\n",
            "('best.This', 'NN')\n",
            "('film', 'NN')\n",
            "('Fonda', 'NNP')\n",
            "('De', 'NNP')\n",
            "('Niro', 'NNP')\n",
            "('fans', 'NNS')\n",
            "('people', 'NNS')\n",
            "('age', 'NN')\n",
            "('love', 'NN')\n",
            "('stories', 'NNS')\n",
            "('coartship', 'NN')\n",
            "('wiser', 'NN')\n",
            "('level.It', 'NN')\n",
            "('people', 'NNS')\n",
            "('matter', 'NN')\n",
            "('illiteracy', 'NN')\n",
            "('.......', 'NN')\n",
            "--------------------\n",
            "--- POS tags for pos7 ---\n",
            "('Stanley', 'NNP')\n",
            "('Iris', 'NNP')\n",
            "('film', 'NN')\n",
            "('acting', 'NN')\n",
            "('Jane', 'NNP')\n",
            "('Fonda', 'NNP')\n",
            "('Robert', 'NNP')\n",
            "('De', 'NNP')\n",
            "('Niro', 'NNP')\n",
            "('movie', 'NN')\n",
            "('fan', 'NN')\n",
            "('Fonda', 'NNP')\n",
            "('work', 'NN')\n",
            "('time', 'NN')\n",
            "('De', 'NNP')\n",
            "('Niro', 'NNP')\n",
            "('ability', 'NN')\n",
            "('role', 'NN')\n",
            "('gold', 'NN')\n",
            "('performance', 'NN')\n",
            "('film', 'NN')\n",
            "('scene', 'NN')\n",
            "('father', 'NN')\n",
            "('home', 'NN')\n",
            "('people', 'NNS')\n",
            "('heart', 'NN')\n",
            "('film', 'NN')\n",
            "('entertainment', 'NN')\n",
            "('bette', 'NN')\n",
            "--------------------\n",
            "--- POS tags for pos8 ---\n",
            "('drama', 'NN')\n",
            "('areas', 'NNS')\n",
            "('viewers', 'NNS')\n",
            "('action', 'NN')\n",
            "('life', 'NN')\n",
            "('way', 'NN')\n",
            "('someone', 'NN')\n",
            "('film', 'NN')\n",
            "('world', 'NN')\n",
            "('wife', 'NN')\n",
            "('supporter', 'NN')\n",
            "('relatives', 'NNS')\n",
            "('quarrels', 'NNS')\n",
            "('child', 'NN')\n",
            "('school', 'NN')\n",
            "('jackass', 'NN')\n",
            "('husband', 'NN')\n",
            "('egg', 'NN')\n",
            "('buys', 'NNS')\n",
            "('beer', 'NN')\n",
            "--------------------\n",
            "--- POS tags for pos9 ---\n",
            "('Working-class', 'NNP')\n",
            "('drama', 'NN')\n",
            "('director', 'NN')\n",
            "('Martin', 'NNP')\n",
            "('Ritt', 'NNP')\n",
            "('moments', 'NNS')\n",
            "('pleasure', 'NN')\n",
            "('charisma', 'NN')\n",
            "('stars', 'NNS')\n",
            "('Jane', 'NNP')\n",
            "('Fonda', 'NNP')\n",
            "('Robert', 'NNP')\n",
            "('De', 'NNP')\n",
            "('Niro', 'NNP')\n",
            "('terrific', 'NN')\n",
            "('widow', 'NN')\n",
            "('illiterate', 'NN')\n",
            "('closet-inventor', 'NN')\n",
            "('rest', 'NN')\n",
            "('Adaptation', 'NNP')\n",
            "('Pat', 'NNP')\n",
            "('Barker', 'NNP')\n",
            "('novel', 'NN')\n",
            "('Union', 'NNP')\n",
            "('Street', 'NNP')\n",
            "('title', 'NN')\n",
            "('bland', 'NN')\n",
            "('film', 'NN')\n",
            "('editing', 'NN')\n",
            "('mess', 'NN')\n",
            "('fantasy', 'NN')\n",
            "('overtures', 'NNS')\n",
            "('issues', 'NNS')\n",
            "('illiteracy', 'NN')\n",
            "('angle', 'NN')\n",
            "('plot-tool', 'NN')\n",
            "('story', 'NN')\n",
            "('fireworks', 'NNS')\n",
            "('characters', 'NNS')\n",
            "('bit', 'NN')\n",
            "('colorless', 'NN')\n",
            "('leads', 'NNS')\n",
            "('degree', 'NN')\n",
            "('finale', 'NN')\n",
            "('fluff', 'NN')\n",
            "('cynics', 'NNS')\n",
            "('characters', 'NNS')\n",
            "('picture', 'NN')\n",
            "('way', 'NN')\n",
            "('*', 'NN')\n",
            "('*', 'NNP')\n",
            "('*', 'NNP')\n",
            "('*', 'NNP')\n",
            "('*', 'NN')\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, pos_tags in pos_dict.items():\n",
        "  print(f\"--- POS tags for {i} ---\")\n",
        "  for j in pos_tags:\n",
        "    if j[1].startswith('VB'):\n",
        "      print(j)\n",
        "  print(\"-\" * 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVG1ZBUHZTOI",
        "outputId": "d594b40e-e38b-4442-9398-ad8a429b5afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- POS tags for pos0 ---\n",
            "('is', 'VBZ')\n",
            "('ran', 'VBD')\n",
            "('lead', 'VB')\n",
            "('believe', 'VB')\n",
            "('is', 'VBZ')\n",
            "('is', 'VBZ')\n",
            "('survive', 'VB')\n",
            "('see', 'VB')\n",
            "('remind', 'VBP')\n",
            "('knew', 'VBD')\n",
            "('saw', 'VBD')\n",
            "('tried', 'VBD')\n",
            "('burn', 'VB')\n",
            "('recalled', 'VBD')\n",
            "(\"'m\", 'VBP')\n",
            "('sack', 'VB')\n",
            "('expect', 'VBP')\n",
            "('think', 'VBP')\n",
            "('is', 'VBZ')\n",
            "('fetched', 'VBN')\n",
            "('is', 'VBZ')\n",
            "--------------------\n",
            "--- POS tags for pos1 ---\n",
            "('like', 'VBP')\n",
            "('is', 'VBZ')\n",
            "('have', 'VBP')\n",
            "('given', 'VBN')\n",
            "('exploding', 'VBG')\n",
            "('behaved', 'VBN')\n",
            "('think', 'VBP')\n",
            "('is', 'VBZ')\n",
            "('are', 'VBP')\n",
            "('going', 'VBG')\n",
            "(\"'s\", 'VBZ')\n",
            "('is', 'VBZ')\n",
            "('did', 'VBD')\n",
            "('know', 'VB')\n",
            "('came', 'VBD')\n",
            "('is', 'VBZ')\n",
            "--------------------\n",
            "--- POS tags for pos2 ---\n",
            "('is', 'VBZ')\n",
            "('scripted', 'VBN')\n",
            "('delivered', 'VBN')\n",
            "('searing', 'VBG')\n",
            "('leaves', 'VBZ')\n",
            "('rolling', 'VBG')\n",
            "(\"'s\", 'VBZ')\n",
            "('are', 'VBP')\n",
            "('caricatured', 'VBN')\n",
            "('be', 'VB')\n",
            "('Following', 'VBG')\n",
            "('does', 'VBZ')\n",
            "('shy', 'VB')\n",
            "('parodying', 'VBG')\n",
            "('enjoy', 'VBP')\n",
            "('are', 'VBP')\n",
            "('poke', 'VB')\n",
            "('disappoint', 'VB')\n",
            "--------------------\n",
            "--- POS tags for pos3 ---\n",
            "('said', 'VBD')\n",
            "('stopped', 'VBD')\n",
            "('is', 'VBZ')\n",
            "('including', 'VBG')\n",
            "('was', 'VBD')\n",
            "('said', 'VBD')\n",
            "('is', 'VBZ')\n",
            "('needs', 'VBZ')\n",
            "('needs', 'VBZ')\n",
            "('bring', 'VBP')\n",
            "('have', 'VBP')\n",
            "('go', 'VB')\n",
            "('listened', 'VBD')\n",
            "('does', 'VBZ')\n",
            "('mean', 'VB')\n",
            "('have', 'VB')\n",
            "('been', 'VBN')\n",
            "('said', 'VBD')\n",
            "--------------------\n",
            "--- POS tags for pos4 ---\n",
            "('is', 'VBZ')\n",
            "('preserved', 'VBN')\n",
            "(\"'s\", 'VBZ')\n",
            "('is', 'VBZ')\n",
            "('disturbing', 'VBG')\n",
            "('wants', 'VBZ')\n",
            "('outlaw', 'VB')\n",
            "('trashing', 'VBG')\n",
            "('is', 'VBZ')\n",
            "('being', 'VBG')\n",
            "(\"'s\", 'VBZ')\n",
            "('do', 'VBP')\n",
            "('conform', 'VB')\n",
            "('therefore', 'VB')\n",
            "('be', 'VB')\n",
            "('removed', 'VBN')\n",
            "('tells', 'VBZ')\n",
            "('falls', 'VBZ')\n",
            "(\"'s\", 'VBZ')\n",
            "(\"'s\", 'VBZ')\n",
            "('stifling', 'VBG')\n",
            "('>', 'VBZ')\n",
            "('won', 'VBD')\n",
            "('toured', 'VBD')\n",
            "('influenced', 'VBD')\n",
            "('came', 'VBD')\n",
            "('have', 'VBP')\n",
            "('preserved', 'VBN')\n",
            "('was', 'VBD')\n",
            "('conceived', 'VBN')\n",
            "('directed', 'VBD')\n",
            "('is', 'VBZ')\n",
            "('is', 'VBZ')\n",
            "('storytelling', 'VBG')\n",
            "('forget', 'VB')\n",
            "('change', 'VB')\n",
            "('see', 'VBP')\n",
            "--------------------\n",
            "--- POS tags for pos5 ---\n",
            "('came', 'VBD')\n",
            "('had', 'VBD')\n",
            "('looked', 'VBD')\n",
            "('see', 'VBP')\n",
            "('has', 'VBZ')\n",
            "('received', 'VBN')\n",
            "(\"'m\", 'VBP')\n",
            "('regarding', 'VBG')\n",
            "('caught', 'VBD')\n",
            "('watched', 'VBD')\n",
            "('written', 'VBN')\n",
            "('was', 'VBD')\n",
            "('discovered', 'VBD')\n",
            "('have', 'VB')\n",
            "('been', 'VBN')\n",
            "('written', 'VBN')\n",
            "('has', 'VBZ')\n",
            "('written', 'VBN')\n",
            "('associates', 'VBZ')\n",
            "('has', 'VBZ')\n",
            "('written', 'VBN')\n",
            "('surpasses', 'VBZ')\n",
            "(\"'ve\", 'VBP')\n",
            "('heard', 'VBN')\n",
            "('keeping', 'VBG')\n",
            "('Can', 'VBP')\n",
            "('like', 'VBP')\n",
            "('was', 'VBD')\n",
            "('deVito', 'VBP')\n",
            "('tell', 'VBP')\n",
            "('be', 'VB')\n",
            "('told', 'VBN')\n",
            "('is', 'VBZ')\n",
            "--------------------\n",
            "--- POS tags for pos6 ---\n",
            "('drama/love', 'VBD')\n",
            "('focuses', 'VBZ')\n",
            "('finding', 'VBG')\n",
            "('thru', 'VBD')\n",
            "('is', 'VBZ')\n",
            "('fails', 'VBZ')\n",
            "('directing', 'VBG')\n",
            "('is', 'VBZ')\n",
            "('be', 'VB')\n",
            "('enjoyed', 'VBN')\n",
            "('love', 'VBP')\n",
            "('is', 'VBZ')\n",
            "('be', 'VB')\n",
            "('interesting', 'VBG')\n",
            "('are', 'VBP')\n",
            "('regarding', 'VBG')\n",
            "--------------------\n",
            "--- POS tags for pos7 ---\n",
            "('did', 'VBD')\n",
            "('did', 'VBD')\n",
            "('admire', 'VB')\n",
            "('are', 'VBP')\n",
            "('have', 'VBP')\n",
            "('been', 'VBN')\n",
            "('is', 'VBZ')\n",
            "('has', 'VBZ')\n",
            "('make', 'VB')\n",
            "('portrays', 'VBZ')\n",
            "('acting', 'VBG')\n",
            "('gives', 'VBZ')\n",
            "('is', 'VBZ')\n",
            "('has', 'VBZ')\n",
            "('take', 'VB')\n",
            "('care', 'VB')\n",
            "('anymore', 'VBP')\n",
            "('break', 'VB')\n",
            "('recommend', 'VB')\n",
            "('say', 'VB')\n",
            "('see', 'VB')\n",
            "('acting', 'VBG')\n",
            "--------------------\n",
            "--- POS tags for pos8 ---\n",
            "('appeared', 'VBD')\n",
            "('have', 'VB')\n",
            "('leaving', 'VBG')\n",
            "('fill', 'VB')\n",
            "('imagine', 'VB')\n",
            "('being', 'VBG')\n",
            "('read', 'VB')\n",
            "('write', 'VB')\n",
            "('smacked', 'VBD')\n",
            "('is', 'VBZ')\n",
            "('gets', 'VBZ')\n",
            "('knocked', 'VBD')\n",
            "('drops', 'VBZ')\n",
            "('takes', 'VBZ')\n",
            "('thumbs', 'VBD')\n",
            "--------------------\n",
            "--- POS tags for pos9 ---\n",
            "('is', 'VBZ')\n",
            "('come', 'VBP')\n",
            "('are', 'VBP')\n",
            "(\"'s\", 'VBZ')\n",
            "('move', 'VB')\n",
            "(\"'s\", 'VBZ')\n",
            "('guess', 'VB')\n",
            "('is', 'VBZ')\n",
            "('verges', 'VBZ')\n",
            "('is', 'VBZ')\n",
            "(\"'s\", 'VBZ')\n",
            "('are', 'VBP')\n",
            "('is', 'VBZ')\n",
            "('ensuing', 'VBG')\n",
            "('love', 'VB')\n",
            "('are', 'VBP')\n",
            "('are', 'VBP')\n",
            "('toned', 'VBN')\n",
            "('is', 'VBZ')\n",
            "('find', 'VB')\n",
            "('swallow', 'VB')\n",
            "('deserve', 'VBP')\n",
            "('ending', 'VBG')\n",
            "('be', 'VB')\n",
            "('satisfying', 'VBG')\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff1272b1",
        "outputId": "1777abf7-c90b-4b3c-dd50-015a5af2139a"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stopword_counts = {}\n",
        "for token_name, tokens in token_dict.items():\n",
        "    count = sum(1 for word in tokens if word.lower() in stop_words)\n",
        "    stopword_counts[token_name] = count\n",
        "for token_name, count in stopword_counts.items():\n",
        "    print(f\"Number of stopwords in {token_name}: {count}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of stopwords in token0: 68\n",
            "Number of stopwords in token1: 40\n",
            "Number of stopwords in token2: 45\n",
            "Number of stopwords in token3: 58\n",
            "Number of stopwords in token4: 107\n",
            "Number of stopwords in token5: 114\n",
            "Number of stopwords in token6: 34\n",
            "Number of stopwords in token7: 60\n",
            "Number of stopwords in token8: 44\n",
            "Number of stopwords in token9: 71\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FiT1m6tleJET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60343037",
        "outputId": "7224f91c-ab79-4ac8-f5e5-ac540c624ffc"
      },
      "source": [
        "unique_words_dict = {}\n",
        "for token_name, tokens in token_dict.items():\n",
        "    unique_words = set(tokens)\n",
        "    unique_words_dict[token_name] = unique_words\n",
        "for token_name, unique_words in unique_words_dict.items():\n",
        "    print(f\"--- Unique words in {token_name} ---\")\n",
        "    print(unique_words)\n",
        "    print(\"-\" * 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Unique words in token0 ---\n",
            "{\"n't\", 'When', 'same', 'as', 'which', 'such', 'High', 'reality', ',', 'recalled', 'episode', 'A', 'other', '..........', 'knew', 'to', 'lead', 'here', 'sack', 'pettiness', 'is', 'pomp', '!', 'teaching', 'at', 'and', 'immediately', 'schools', 'I', 'survive', 'some', 'who', 'their', 'Teachers', 'pity', 'programs', \"''\", '.........', 'profession', 'situation', '.', 'that', 'fetched', 'STUDENT', 'through', 'comedy', 'Welcome', 'Bromwell', 'think', 'insightful', 'My', 'of', 'students', 'INSPECTOR', 'age', 'one', \"'\", '35', 'life', 'much', 'right', 'burn', 'student', 'It', 'scramble', 'years', 'classic', '``', 'it', 'a', 'tried', 'the', 'my', 'school', 'repeatedly', 'closer', 'teachers', ':', \"'m\", 'expect', 'believe', 'line', 'adults', 'satire', 'than', 'about', 'down', 'can', 'far', 'me', 'The', 'cartoon', 'saw', 'whole', 'your', 'all', \"'s\", 'in', 'time', 'many', 'see', 'remind', 'What', 'ran', 'pathetic', 'financially'}\n",
            "--------------------\n",
            "--- Unique words in token1 ---\n",
            "{\"n't\", 'very', 'Park', 'High', 'came', 'given', ',', 'Natella', 'idiotic', 'Mark', 'is', '!', 'Oberman', 'Mackichan', 'at', 'and', 'Very', 'Henry', 'I', 'bitches', 'Latrina', 'teenage', 'from', 'others', 'cartoons', 'leader', 'Keisha', 'then', 'Blunder', 'sweets', 'have', 'If', 'Ringers', 'Nina', 'Maths', '.', 'comedy', 'Bromwell', 'teacher', 'this', 'think', 'Watts', 'EastEnders', 'of', 'adult', 'going', 'fantastic', 'good', 'on', 'girls', 'exploding', \"'\", 'Dead', 'There', 'know', 'adventures', 'South', 'it', 'a', 'the', 'also', 'with', 'school', 'but', 'cast', 'like', 'Tracy-Ann', 'nearly', 'teachers', 'Conti', 'Bip', 'Doon', 'Mr.', 'nervous', 'Chrissie', 'Pony', 'are', 'stories', 'about', 'Perry', 'format', 'small', 'three', 'The', 'Lenny', 'did', 'Canada', 'principal', 'you', 'similar', 'Smack', 'behaved', \"'s\", 'Gina', 'many', 'Yashere'}\n",
            "--------------------\n",
            "--- Unique words in token2 ---\n",
            "{\"n't\", 'not', 'brilliant', ')', 'High', 'caricatured', 'disappoint', ',', 'every', 'episode', 'provocative', 'our', 'Natella', 'superbly', 'to', 'protagonists', 'term', 'parody', 'is', 'better', '!', 'and', 'at', 'Political', 'Following', 'Latrina', 'from', 'Keisha', 'then', \"''\", 'scripted', 'imaginable', 'more', 'escapades', 'searing', 'If', '.', 'parodying', 'that', 'Bromwell', 'flies', 'this', 'leaves', 'shows', 'of', 'students', 'correctness', 'away', 'Expertly', 'Public', 'subject', 'British', 'It', 'vulgar', 'South', 'enjoy', '``', 'a', 'any', 'the', 'out', 'nothing', 'does', 'with', 'School', '(', 'be', 'short', 'witty', 'taboo', 'teachers', 'perfectly', 'or', 'accurate', 'rolling', 'will', 'section', 'sharp', 'are', 'poke', 'shy', 'fun', 'characters', 'want', 'The', 'three', 'for', 'laughter', 'society', 'delivered', 'you', 'London', \"'s\", 'in', 'show', 'window', 'literally', 'cross', 'afraid'}\n",
            "--------------------\n",
            "--- Unique words in token3 ---\n",
            "{'pit', 'not', ',', 'itself', 'was', 'listened', 'to', 'Who', 'something', 'its', 'attention', 'needs', 'is', '!', '<', 'and', 'at', 'including', 'orchestra', 'Hey', 'sometimes', 'people', 'story', '--', \"''\", 'door', 'more', 'have', 'experiment', '.', 'that', 'br', 'world', 'audience', 'one', '/', 'said', 'we', 'theatre', '``', 'it', 'a', 'mean', 'the', 'stopped', 'been', 'Sometimes', 'does', 'film', 'but', 'even', 'like', 'Alas', 'participants', ':', 'or', 'theatrical', 'than', 'hell', 'actors', 'This', 'grand', 'active', '?', 'go', 'you', 'your', 'stage', \"'s\", '>', 'should', 'participation', 'in', 'Why', 'experience', 'All', 'no', 'bring'}\n",
            "--------------------\n",
            "--- Unique words in token4 ---\n",
            "{\"n't\", 'origins', 'not', 'brilliant', 'by', 'as', 'serious', ')', 'marriage', 'wants', 'relevant', 'came', 'gay', ',', 'directed', 'was', 'our', 'won', 'director', 'violence', 'must', 'to', 'therefore', 'something', 'movement', 'its', 'original', 'preserved', 'morality', 'version', 'here', 'storytelling', 'now', 'man', 'is', 'Europe', '<', 'conformity', 'and', 'fable', 'only', 'deeply', 'Christ', 'U.S.', 'Jesus', 'imaginative', 'almost', 'who', 'Broadway', 'surface', 'unsettling', 'And', 'from', 'others', 'story', '--', 'more', 'an', 'have', 'animals', '.', 'that', 'through', 'br', 'Congress', 'this', 'world', 'darkly', 'of', 'genuinely', 'really', 'hate', 'Constitution', 'emotional', 'kind', 'toured', 'on', 'studio', 'after', '/', 'originally', '...', 'revenge', 'change', 'much', 'aggressive', 'New', 'disturbing', 'Off', 'wildly', 'bigger', 'On', 'tells', 'falls', 'we', 'theatre', \"O'Horgan\", 'never', 'it', 'a', 'the', 'any', 'York', 'also', 'film', 'with', 'do', 'personal', '(', 'be', 'Superstar', 'but', 'even', 'love', 'America.', 'acclaim', 'cast', 'like', 'sex', 'great', 'social', 'piece', 'just', 'stifling', 'mainstream', 'being', 'conform', 'HAIR', \"'ll\", 'international', '1960s', 'might', 'often', 'everyone', 'Tom', 'about', 'This', 'glorious', 'pretty', 'funny', 'conceived', 'Though', 'for', 'trashing', 'The', 'norms', 'though', 'easy-to-take', 'pig', 'you', 'influenced', 'tale', 'liberty', 'FUTZ', 'stage', 'way', 'outlaw', 'all', \"'s\", '>', 'production', 'in', 'experimental', 'show', 'time', 'removed', 'Luckily', 'when', 'see', 'forget'}\n",
            "--------------------\n",
            "--- Unique words in token5 ---\n",
            "{\"n't\", 'Konrack', 'heard', 'by', 'as', 'which', 'Schindler', 'such', 'still', 'what', 'movies', 'came', 'another', 'enough', ',', 'Coplandesque', 'side', 'credits', 'was', 'Renaissance', 'other', 'to', 'Can', 'title', 'genre', 'How', 'its', 'True', 'keeping', 'reception', 'attention', 'if', 'here', 'watched', 'addition', 'is', 'spiritual', 'looked', 'and', 'tender', 'I', 'anything', 'bombasticities', 'John', 'up', 'sensitive', 'sensitivity', 'And', 'Valley', 'Voigt', 'movie', 'he', 'ever', 'caught', 'story', 'intellectual', 'tenderness', 'Danny', 'ca', 'tell', 'has', 'more', 'an', 'have', '.', 'that', 'surpasses', 'Man', 'this', 'told', 'wit', 'Stanley', 'shows', 'My', 'of', 'etc', 'really', 'opinion', 'one', 'on', 'excellent', 'regarding', 'Wars', 'Catch', 'discovered', 'where', 'List', 'usually', 'But', 'scores', 'idea', 'name', 'mixed', 'score', 'South', 'associates', 'it', 'been', 'a', 'any', 'the', 'recent', 'They', 'my', 'Star', 'film', 'positive', 'with', 'beautiful', 'be', 'plot', 'sophistication', 'but', 'middle', 'even', 'none', 'till', 'Iris', 'like', 'so', ':', 'written', 'American', 'great', \"'m\", 'style', 'Me', 'or', 'poignant', 'You', 'awakening', 'charges', 'beauty', 'African', 'Americana', 'fully', 'received', 'lovely', 'often', 'than', 'Williams', 'about', 'This', 'his', 'for', 'education', 'As', 'himself', 'Carolina', 'your', \"'ve\", 'commentators', \"'s\", 'deVito', 'in', 'Green', 'had', 'see', 'surprise', 'when', 'no', 'young', 'necessary', 'thing'}\n",
            "--------------------\n",
            "--- Unique words in token6 ---\n",
            "{'screenplay', 'De', 'fans', 'are', 'life', 'who', 'stories', '.......', 'by', 'blue', 'regarding', 'new', 'cautious', 'would', 'illiteracy', 'fails', 'where', 'people', 'movie', 'cinematography', 'level.It', 'story', 'subject', 'average', 'best.This', 'thru', 'editing.The', ',', 'more', 'for', 'enjoyed', 'love.The', 'lives', 'interested', 'a', 'the', 'focuses', 'that', 'matter', 'drama/love', 'also', 'wiser', 'film', 'story/script', 'be', 'but', 'middle', 'love', 'Fonda', 'finding', 'acting', 'directing', 'in', 'of', 'here', 'coartship', 'age', 'is', 'good', 'will', 'Niro', 'Fair', 'and', 'on', 'collar', 'at', 'only', 'interesting'}\n",
            "--------------------\n",
            "--- Unique words in token7 ---\n",
            "{\"n't\", 'always', 'same', 'as', 'fan', 'admire', 'portrays', 'recommend', 'ability', ',', 'every', 'He', 'father', 'Robert', 'to', 'into', 'say', 'here', 'is', 'wo', 'heart', 'and', 'at', 'I', 'him', '&', 'care', 'would', 'people', 'movie', 'cinematic', 'he', 'bette', 'ca', 'has', 'have', 'strong', '.', 'that', 'this', 'Fonda', 'acting', 'Stanley', 'of', 'really', 'role', 'elderly', 'anywhere', 'gold', 'much', 'where', 'there', 'gives', 'Although', 'take', 'delicate', 'been', 'home', 'a', 'the', 'tremendously', 'film', 'but', 'Iris', 'like', 'great', 'because', 'entertainment', 'scene', 'Jane', 'she', 'anymore', 'will', 'Niro', 'De', 'are', 'work', 'his', 'performance', 'for', 'did', 'break', 'you', 'your', \"'s\", 'in', 'time', 'see', 'make'}\n",
            "--------------------\n",
            "--- Unique words in token8 ---\n",
            "{'husband', 'life', 'who', 'up', 'fill', 'write', 'their', 'areas', 'This', 'few', 'takes', 'then', 'jackass', 'can', ',', 'imagine', 'neither', 'real', 'for', 'have', 'wife', 'it', '.', 'a', 'live-in', 'the', 'nor', 'to', 'troubled', 'child', 'out', 'blank', 'film', 'sole', 'appeared', 'with', 'school', 'leaving', 'way', 'relatives', 'this', 'nest', 'although', 'world', 'in', 'someone', 'of', 'drops', ':', 'simply', 'thumbs', '2', 'suddenly', 'action', 'supporter', 'is', 'good', 'quarrels', 'themselves', 'drama', 'being', 'read', 'knocked', 'egg', 'and', 'buys', 'viewers', 'beer', 'gets', 'typically', 'smacked', 'Very', 'I'}\n",
            "--------------------\n",
            "--- Unique words in token9 ---\n",
            "{\"n't\", 'come', 'ensuing', 'leads', 'pure', 'as', 'intentionally', 'serious', ')', 'illiteracy', 'still', ',', 'fireworks', 'other', 'Robert', 'director', 'overtures', 'to', 'move', 'issues', 'title', 'cynics', 'deserve', 'blue-collar', 'romantic', 'picture', 'Street', 'Barker', ';', 'is', 'better', '!', 'these', 'and', 'interesting', 'closet-inventor', 'who', 'rest', 'would', 'from', 'satisfying', 'they', 'he', 'plot-tool', 'story', '--', \"''\", 'fluff', 'ca', '*', 'an', '.', 'charisma', 'colorless', 'Fonda', 'ending', 'of', 'find', 'really', 'novel', 'finale', 'on', 'She', 'toned', 'verges', 'bit', 'happy', 'There', 'Adaptation', 'there', 'mostly', 'real', 'mess', '``', 'a', 'it', 'the', 'any', 'film', 'moments', 'difficult', 'laid-back', '(', 'be', 'both', 'but', 'even', 'love', 'so', 'just', 'Jane', 'will', 'drama', 'Niro', 'pleasure', 'guess', 'De', 'are', 'degree', 'unbelievable', 'down', 'widow', 'Martin', 'rosy-hued', 'characters', 'can', 'Pat', 'yet', 'probably', 'swallow', 'editing', 'for', 'The', 'illiterate', 'fantasy', 'though', 'due', 'Working-class', 'stars', 'you', 'two', 'way', 'bland', 'Union', \"'s\", 'Ritt', 'terrific', 'pleasant', 'no', 'angle'}\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ea5ea54a",
        "outputId": "10d6a278-3a14-494d-a112-b7545b289594"
      },
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "pos_tag_counts = {}\n",
        "for token_name, pos_tags in pos_dict.items():\n",
        "    tags = [tag for word, tag in pos_tags]\n",
        "    pos_tag_counts[token_name] = Counter(tags)\n",
        "data = []\n",
        "for token_name in token_dict.keys():\n",
        "    total_words = len(token_dict[token_name])\n",
        "    stopword_count = stopword_counts.get(token_name, 0)\n",
        "    unique_word_count = len(unique_words_dict.get(token_name, set()))\n",
        "    pos_counts = pos_tag_counts.get(token_name, Counter())\n",
        "    TTR=unique_word_count/total_words\n",
        "    row = {\n",
        "        'Review number': token_name,\n",
        "        'Total Words': total_words,\n",
        "        'Stopword Count': stopword_count,\n",
        "        'Unique Word Count': unique_word_count,\n",
        "        'TTR':TTR\n",
        "    }\n",
        "    data.append(row)\n",
        "summary_df = pd.DataFrame(data)\n",
        "summary_df = summary_df.fillna(0)\n",
        "display(summary_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Review number  Total Words  Stopword Count  Unique Word Count       TTR\n",
              "0        token0          165              68                106  0.642424\n",
              "1        token1          138              40                 96  0.695652\n",
              "2        token2          136              45                 99  0.727941\n",
              "3        token3          138              58                 78  0.565217\n",
              "4        token4          292             107                170  0.582192\n",
              "5        token5          255             114                164  0.643137\n",
              "6        token6           88              34                 68  0.772727\n",
              "7        token7          136              60                 89  0.654412\n",
              "8        token8           99              44                 73  0.737374\n",
              "9        token9          195              71                130  0.666667"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb4b51b7-3fcc-41ba-b35f-4f1c8dde560d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review number</th>\n",
              "      <th>Total Words</th>\n",
              "      <th>Stopword Count</th>\n",
              "      <th>Unique Word Count</th>\n",
              "      <th>TTR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>token0</td>\n",
              "      <td>165</td>\n",
              "      <td>68</td>\n",
              "      <td>106</td>\n",
              "      <td>0.642424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>token1</td>\n",
              "      <td>138</td>\n",
              "      <td>40</td>\n",
              "      <td>96</td>\n",
              "      <td>0.695652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>token2</td>\n",
              "      <td>136</td>\n",
              "      <td>45</td>\n",
              "      <td>99</td>\n",
              "      <td>0.727941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>token3</td>\n",
              "      <td>138</td>\n",
              "      <td>58</td>\n",
              "      <td>78</td>\n",
              "      <td>0.565217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>token4</td>\n",
              "      <td>292</td>\n",
              "      <td>107</td>\n",
              "      <td>170</td>\n",
              "      <td>0.582192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>token5</td>\n",
              "      <td>255</td>\n",
              "      <td>114</td>\n",
              "      <td>164</td>\n",
              "      <td>0.643137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>token6</td>\n",
              "      <td>88</td>\n",
              "      <td>34</td>\n",
              "      <td>68</td>\n",
              "      <td>0.772727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>token7</td>\n",
              "      <td>136</td>\n",
              "      <td>60</td>\n",
              "      <td>89</td>\n",
              "      <td>0.654412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>token8</td>\n",
              "      <td>99</td>\n",
              "      <td>44</td>\n",
              "      <td>73</td>\n",
              "      <td>0.737374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>token9</td>\n",
              "      <td>195</td>\n",
              "      <td>71</td>\n",
              "      <td>130</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb4b51b7-3fcc-41ba-b35f-4f1c8dde560d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb4b51b7-3fcc-41ba-b35f-4f1c8dde560d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb4b51b7-3fcc-41ba-b35f-4f1c8dde560d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dd7c86dc-d8ec-4657-903d-ce170af22595\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd7c86dc-d8ec-4657-903d-ce170af22595')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dd7c86dc-d8ec-4657-903d-ce170af22595 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_b17101c5-31dd-4939-a4f7-f9feb14cc7a4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b17101c5-31dd-4939-a4f7-f9feb14cc7a4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary_df",
              "summary": "{\n  \"name\": \"summary_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Review number\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"token8\",\n          \"token1\",\n          \"token5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 65,\n        \"min\": 88,\n        \"max\": 292,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          138,\n          88,\n          165\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stopword Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27,\n        \"min\": 34,\n        \"max\": 114,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          44,\n          40,\n          114\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unique Word Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36,\n        \"min\": 68,\n        \"max\": 170,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          73,\n          96,\n          164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TTR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06626388059531396,\n        \"min\": 0.5652173913043478,\n        \"max\": 0.7727272727272727,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7373737373737373,\n          0.6956521739130435,\n          0.6431372549019608\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xgO0rLYFe0ij"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}